---
title: "customer_churn_logisticregression_AnalyticsVidhya"
author: "HARSHITHA MEKALA"
date: "4 September 2018"
output: html_document
---

# loading Libraries
```{r}
library(tidyverse)
library(MASS)
library(car)
library(e1071)
library(cowplot)
library(caret)
library(caTools)
library(pROC)

```
# loading dataset
```{r}
telco <- read.csv("E://Machine Learning/My practice/AnalyticsVidhya_dataset/WA_Fn-UseC_-Telco-Customer-Churn.csv")

#View(telco)
glimpse(telco)


```

# Visualizing the missing data
```{r}
options(repr.plot.width = 6, repr.plot.height = 4)
missing_data <- telco %>% summarise_all(funs(sum(is.na(.))/n()))
missing_data <- gather(missing_data, key = "variables", value = "percent_missing")

ggplot(missing_data, aes(x = reorder(variables, percent_missing), 
                         y = percent_missing)) +
  geom_bar(stat = "identity", 
           fill = "red", 
           aes(color = I('white')), 
           size = 0.3) +
  xlab('variables') +
  coord_flip() +
  theme_bw()
  

# so here there are only 11% of missing values. so we can remove them easily using complete.cases()

telco <- telco[complete.cases(telco),]
sum(is.na(telco$TotalCharges)) # cross checking for NA

# changing senior citizens to factor from int

telco$SeniorCitizen <- as.factor(ifelse(telco$SeniorCitizen == 1, "Yes", "No"))
class(telco$SeniorCitizen)
```

```{r}
theme1 <- theme_bw() +
  theme(axis.text.x = element_text(angle = 0, 
                                   hjust = 1,
                                   vjust = 0.5),
        legend.position = "none")


theme2 <- theme_bw() +
  theme(axis.title.x = element_text(angle = 90,
                                    hjust = 1,
                                    vjust = 0.5),
        legend.position = "none")


glimpse(telco)
```

## visualizing the categorical columns w.r.t churn
```{r}

# cheching the churn rate in last month

table(telco$Churn)
table(telco$Churn)/nrow(telco)

# about 26% of the people left the platfrom within last month
```

# visualising the churn rate
```{r}
options(repr.plot.height = 4, repr.plot.width = 6)

telco %>% 
  group_by(Churn) %>% 
  summarise(Count = n()) %>% 
  mutate(percent = prop.table(Count)*100) %>% 
  ggplot(aes(reorder(Churn, -percent), percent), fill = Churn) +
  geom_col(fill = c("#FC4E07", "#E7B800")) +
  geom_text(aes(label = sprintf("%.2f%%", percent)), 
            hjust = 0.01, 
            vjust = -0.5, 
            size = 3) +
  theme_bw() +
  xlab("Churn") +
  ylab("percent") +
  ggtitle("Churn percent")
  

```

# visualizing the othet attributes w.r.t. churn rate
```{r}
options(repr.plot.width = 12, repr.plot.height = 8)

plot_grid(ggplot(telco, aes(x = gender,fill = Churn)) + geom_bar() + theme1,
          ggplot(telco, aes(x = SeniorCitizen, fill = Churn)) + geom_bar(position = "fill") + theme1,
          ggplot(telco, aes(x = Partner,fill = Churn)) + geom_bar(position = "fill") + theme1,
          ggplot(telco, aes(x = Dependents,fill = Churn)) + geom_bar(position = "fill") + theme1,
          ggplot(telco, aes(x = PhoneService,fill = Churn)) + geom_bar(position = "fill") + theme1,
          ggplot(telco, aes(x = MultipleLines,fill = Churn)) + geom_bar(position = "fill") + theme_bw() +
          scale_x_discrete(labels = function(x) str_wrap(x, width = 10)), 
          align = "h")
          

# the churn is almost same in male and female
# The percent of churn is higher in case of senior citizens
# Customers with Dependents nd Partner has lower churn rate when compaterd to others

```



```{r}
options(repr.plot.width = 12, repr.plot.height = 8)

plot_grid(ggplot(telco, aes(x=InternetService, fill = Churn))+ geom_bar(position = "fill") + theme1 +
            scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),
          ggplot(telco, aes(x=OnlineSecurity, fill = Churn))+ geom_bar(position = "fill") + theme1 +
            scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),
          ggplot(telco, aes(x=OnlineBackup, fill = Churn))+ geom_bar(position = "fill") + theme1 +
            scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),
          ggplot(telco, aes(x=DeviceProtection, fill = Churn))+ geom_bar(position = "fill") + theme1 +
            scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),
          ggplot(telco, aes(x=TechSupport, fill = Churn))+ geom_bar(position = "fill") + theme1 +
            scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),
          ggplot(telco, aes(x=StreamingTV, fill = Churn))+ geom_bar(position = "fill") + theme_bw() +
          scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),
          align = "h")

# churn rate is much high in Fiber optic Internet services
# Customers who do not have services like No Online Security,Online Backup and Tech support have left the platform in the past month 
```




```{r}
#options(repr.plot.width = 12, repr.plot.height = 8)

plot_grid(ggplot(telco, aes(x = StreamingMovies, fill = Churn)) + geom_bar(position = "fill") + theme1 +
            scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),
          ggplot(telco, aes(x = Contract, fill = Churn)) + geom_bar(position = "fill") + theme1 +
            scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),
          ggplot(telco, aes(x = PaperlessBilling, fill = Churn)) + geom_bar(position = "fill") + theme1 +
            scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),
          ggplot(telco, aes(x = PaymentMethod, fill = Churn)) + geom_bar(position = "fill") + theme_bw() +
            scale_x_discrete(labels = function(x) str_wrap(x, width = 10)), 
          align = "h")
# Percrnt of people who churn arehigh in Mot-month subscription
# churn rate is also high in PaperlessBilling
# churn rate is high in Electronic Check
```

## Analysing the continuous variables w.r.t churn

```{r}

options(repr.plot.width = 6, repr.plot.height = 2)

ggplot(telco, aes(y = tenure, x = "", fill = Churn)) + 
         geom_boxplot() +
         theme_bw() +
         xlab(" ")

# The median tenure of customers who left are around 10 months.
```

```{r}
options(repr.plot.width = 6, repr.plot.height = 2)

ggplot(telco, aes(y = MonthlyCharges, x = "", fill = Churn)) +
  geom_boxplot() +
  theme_bw() +
  xlab(" ")

# Customers who churn had high montly charges, The median is above 75.
```

```{r}
options(repr.plot.width = 6, repr.plot.height = 2)

ggplot(telco, aes(y = TotalCharges, x = (""), fill = Churn)) +
  geom_boxplot() +
  theme_bw() +
  xlab(" ")

# The median charges of customers who churned is very low  
```

# checking the corelation between continuous variables
```{r}
options(repr.plot.width = 6, repr.plot.height = 4)

telco_cor <- round(cor(telco[, c("tenure", "MonthlyCharges","TotalCharges")]), 1)
telco_cor

```

# Checking for outliers in continuous variables
```{r}
options(repr.plot.width = 4, repr.plot.height = 4)

boxplot(telco$tenure)$out
boxplot(telco$MonthlyCharges)$out
boxplot(telco$TotalCharges)$out

```
## DATA PREPARATION

# cleaning the categorical features
# Standardising continuous features
# Creating derived features
# Creating dummy variables for factor variables
# Creating the final dataset
# Splitting the data into train and validation dataset

# Cleaning the Categorical features

# From the EDA above, we know that there are some categorical features that have 'No' and 'No Internet Service' or 'No Phone Service' as a category, we can make them as 'No' and clean these features.

```{r}
telco <- data.frame(lapply(telco, function(x) {
                    gsub("No internet service", "No", x )}))

telco <- data.frame(lapply(telco, function(x){
  gsub("No phone service", "No", x)}))


```

# standardising the continuous features
```{r}

num_columns <- c("tenure", "MonthlyCharges", "TotalCharges")
telco[num_columns] <- sapply(telco[num_columns], as.numeric)

telco_int <- telco[,c("tenure", "MonthlyCharges", "TotalCharges")]
telco_int <- data.frame(scale(telco_int))

```

# creating derived features
```{r}
# Here we make tenure(age) in different bins

max(telco$tenure)
min(telco$tenure)

telco <- mutate(telco, tenure_bin = tenure)

telco$tenure_bin[telco$tenure_bin >= 0 & telco$tenure_bin <= 12] <- "0-1 Years"
telco$tenure_bin[telco$tenure_bin > 12 & telco$tenure_bin <= 24] <- "1-2 Years"
telco$tenure_bin[telco$tenure_bin > 24 & telco$tenure_bin <= 36] <- "2-3 Years"
telco$tenure_bin[telco$tenure_bin > 36 & telco$tenure_bin <= 48] <- "3-4 Years"
telco$tenure_bin[telco$tenure_bin > 48 & telco$tenure_bin <= 60] <- "4-5 Years"
telco$tenure_bin[telco$tenure_bin > 60 & telco$tenure_bin <= 72] <- "5-6 Years"

telco$tenure_bin <- as.factor(telco$tenure_bin)
class(telco$tenure_bin)

options(repr.plot.width = 4, repr.plot.height = 4)
ggplot(telco, aes(tenure_bin, fill = tenure_bin)) + geom_bar() + theme1


# After checking the distribution of the data in each tenure bin, we found that maximum number of customers # have a tenure of either 0-1 years and followed by 5-6 years.

```
# creating dummy variables
```{r}
telco_cat <- telco[,-c(1,6,19,20)] # removing numeric columns to create dummy for the rest columns

# dummy variables
dummy <- data.frame(sapply(telco_cat, function(x) data.frame(model.matrix(~x-1, data = telco_cat))[,-1]))

head(dummy)

```

# creating the final dataset by combing dummy and numeric ata frames
```{r}
telco_final = cbind(telco_int, dummy)
head(telco_final)

```

# spliting the data into train and validation set 
```{r}
set.seed(123)

indices = sample.split(telco_final$Churn, SplitRatio = 0.7)
train <- telco_final[indices, ]
validation <- telco_final[!(indices),]

```


## MODEL BUILDING 1:

# Starting with Logistic Regression
```{r}
model_1 <- glm(Churn~., data = train, family = "binomial")
summary(model_1)


model_2 <- stepAIC(model_1, direction = "both")
summary(model_2)

"We can use variance inflation factor (vif) to get rid of redundant predictors or the variables that have high multicollinearity between them. Multicollinearity exists when two or more predictor variables are highly related to each other and then it becomes difficult to understand the impact of an independent variable on the dependent variable.

The Variance Inflation Factor(VIF) is used to measure the multicollinearity between predictor variables in a model. A predictor having a VIF of 2 or less is generally considered safe and it can be assumed that it is not correlated with other predictor variables. Higher the VIF, greater is the correlation of the predictor variable w.r.t other predictor variables. However, Predictors with high VIF may have high p-value(or highly significant), hence, we need to see the significance of the Predictor variable before removing it from our model."

vif(model_2)

```

# Removing DeviceProtection since there is less significance though the vif is less than 2
```{r}
#names(train)

model_3 <- glm(formula = Churn ~ tenure + MonthlyCharges + SeniorCitizen + Partner +     InternetService.xFiber.optic + InternetService.xNo + OnlineSecurity + 
OnlineBackup + TechSupport + StreamingTV + Contract.xOne.year + 
Contract.xTwo.year + PaperlessBilling + PaymentMethod.xElectronic.check + 
tenure_bin.x1.2.Years + tenure_bin.x5.6.Years, family = "binomial", data = train)

summary(model_3)
vif(model_3)

```

#Removing StreamingTV  as it has high p-value 
```{r}
model_4 <- glm(formula = Churn ~ tenure + MonthlyCharges + SeniorCitizen + 
    Partner + InternetService.xFiber.optic + InternetService.xNo + 
    OnlineSecurity + OnlineBackup + TechSupport +  
    Contract.xOne.year + Contract.xTwo.year + PaperlessBilling + 
    PaymentMethod.xElectronic.check + tenure_bin.x1.2.Years + 
    tenure_bin.x5.6.Years, family = "binomial", data = train)

summary(model_4)
vif(model_4)

# model_3 has all signidficant features, so lets use this for final prediction
```

```{r}
final_model <- model_3
```

# Model evaluation using validation data
```{r}
pred <- predict(final_model, type = "response", newdata = validation[,-24])
summary(pred)

validation$prob <- pred

# Using probability cut-off of 50% 
pred_churn <- factor(ifelse(pred >= 0.5, "Yes", "No"))
actual_churn <- factor(ifelse(validation$Churn == 1, "Yes", "No"))
table(actual_churn, pred_churn)

```

# let check the accuracy, specificity, sensitivity
```{r}
cutoff_churn <- factor(ifelse(pred >= 0.5, "Yes", "No"))
cutoff_churn
conf_final <- confusionMatrix(cutoff_churn, actual_churn, positive = "Yes")
conf_final

accuracuy <- conf_final$overall[1]
sensitivity <-conf_final$byClass[1]  
specificity <-conf_final$byClass[2]  

#As we can see above, when we are using a cutoff of 0.50, we are getting a good accuracy and specificity, but the sensitivity is very less. Hence, we need to find the optimal probalility cutoff which will give maximum accuracy, sensitivity and specificity

```


```{r}
perform_fn <- function(cutoff)
{
  predicted_churn <- factor(ifelse(pred >= cutoff, "Yes", "No"))
  conf <- confusionMatrix(predicted_churn, actual_churn,positive = "Yes")
  accuracy = conf$overall[1]
  sensitivity = conf$byClass[1]
  specificity = conf$byClass[2]
  out <- t(as.matrix(c(sensitivity, specificity, accuracy)))
  colnames(out) <- c("sensitivity", "specificity", "accuracy")
  return(out) 
}


```

# finding the best cutoff value 
```{r}
options(repr.plot.width =8, repr.plot.height =6)
summary(pred)
s = seq(0.01,0.80,length=100)
OUT = matrix(0,100,3)

for(i in 1:100)
{
  OUT[i,] = perform_fn(s[i])
} 

plot(s, OUT[,1],xlab="Cutoff",ylab="Value",cex.lab=1.5,cex.axis=1.5,ylim=c(0,1),
     type="l",lwd=2,axes=FALSE,col=2)
axis(1,seq(0,1,length=5),seq(0,1,length=5),cex.lab=1.5)
axis(2,seq(0,1,length=5),seq(0,1,length=5),cex.lab=1.5)
lines(s,OUT[,2],col="darkgreen",lwd=2)
lines(s,OUT[,3],col=4,lwd=2)
box()
legend("bottom",col=c(2,"darkgreen",4,"darkred"),text.font =3,inset = 0.02,
       box.lty=0,cex = 0.8, 
       lwd=c(2,2,2,2),c("Sensitivity","Specificity","Accuracy"))

abline(v = 0.32, col="red", lwd=1, lty=2)
axis(1, at = seq(0.1, 1, by = 0.1))

#cutoff <- s[which(abs(OUT[,1]-OUT[,2])<0.01)]
# cutoff value is 0.32. HEnce we choose 0.32 for our final model

```

# final model with 0.32 as our  cutoff value
```{r}
cutoff_churn <- factor(ifelse(pred >= 0.32, "Yes", "No"))
conf_final <- confusionMatrix(cutoff_churn, actual_churn, positive = "Yes")
accuracy <- conf_final$overall[1]
sensitivity <- conf_final$byClass[1]
specificity <- conf_final$byClass[2]
accuracy
sensitivity
specificity


# Logistic Regression with a cutoff probability value of 0.32 gives us better values of accuracy, sensitivity and specificity in the validation data.
```

## MODEL BUILDING 2
# DECISION TREE ALGORITHM
```{r}
#Decision Tree- Splits the data into multiple sets and each set is further split into subsets to arrive at a tree like structure and make a decision. Homogeneity is the basic concept that helps to determine the attribute on which a split should be made. A split that results into the most homogenous subset is often considered better and step by step each attribute is choosen that maximizes the homogeneity of each subset. Further, this homogeneity is measured using different ways such as Gini Index, Entropy and Information Gain.


```

# Preparing the data
```{r}
set.seed(123)
telco_final$Churn <- as.factor(telco_final$Churn)

indices <- sample.split(telco_final$Churn, SplitRatio = 0.7)
train <- telco_final[indices, ]
validation <- telco_final[!(indices),]

```

# Training decision tree momdel using all variables and Predicting w.r.t Validation variables
```{r}
options(repr.plot.weight = 10, repr.plot.height = 8)

library(rpart)
library(rpart.plot)

# Training
Dtree <- rpart(Churn ~ ., data = train, method = "class")
summary(Dtree)

# Predicting using validation data
DTreePred <- predict(Dtree, type = "class", newdata = validation[,-24])


```

# Creating confusion matrix
```{r}
confusionMatrix(validation$Churn, DTreePred)

#The decision tree model (accuracy - 77.3%) gives slightly better accuracy with respect to the logistic regression model (accuracy 75%). The sensitivity is also better in case of Decision tree which is 81.1%. However, the specificity has decreased to 60.8% in case of Decision Tree as compared to logistic regression model.
```

# MODEL BUILDING 3
# RANDOM FOREST MODEL
```{r}
# RANDOM FOREST- Often known as an ensemble of a large number of Decision Trees, that uses bootstrapped aggregation technique to choose random samples from a dataset to train each tree in the forest. The final prediction in a RandomForest is an aggregation of prediction of individual trees. One of the advantages of RandomForest is that, it gives out-of-bag(OOB) error estimates, which is the mean prediction error on a training sample, using the trees that do not have that training sample in their bootstrap sample. It may act as a cross validation error and eliminate the need of using test/validation data, thereby increasing the training the data. However, I am still going to use train and validation concept here as well, like I did in the above two Models.


library(randomForest)
set.seed(123)
telco_final$Churn <- as.factor(telco_final$Churn)

indices = sample.split(telco_final$Churn, SplitRatio = 0.7)
train = telco_final[indices,]
validation = telco_final[!(indices),]
```
# Training the RandomForest Model
```{r}
model.rf <- randomForest(Churn ~ ., data=train, proximity=FALSE,importance = FALSE,
                        ntree=500,mtry=4, do.trace=FALSE)
model.rf

# The OOB error estimate comes to around 20.87%, so the model has around 79% out of sample accuracy for the training set. Let's check the prediction and accuracy on our validation data.
```

# Predciting the validation set and checking the confusion mtrix
```{r}
testPred <- predict(model.rf, newdata = validation[,-24])
table(testPred, validation$Churn)

confusionMatrix(validation$Churn, testPred)

```

# checking the Variable importance plot
```{r}
varImpPlot(model.rf)
```

# selecting the best model using the AUC curve
```{r}
options(repr.plot.weight = 10, repr.plot.height = 8)

glm.roc <- roc(response = validation$Churn, predictor = as.numeric(pred))
DT.roc <- roc(response = validation$Churn, predictor = as.numeric(DTreePred)) 
rf.roc <- roc(response = validation$Churn, predictor = as.numeric(testPred))

plot(glm.roc, legacy.axes = TRUE, print.auc.y = 1.0, print.auc = TRUE)
plot(DT.roc, col = "blue", add = TRUE, print.auc.y = 0.65, print.auc = TRUE)
plot(rf.roc, col = "red" , add = TRUE, print.auc.y = 0.85, print.auc = TRUE)

legend("bottom", c("Random Forest", "Decision Tree", "Logistic"),
    lty = c(1,1), 
    lwd = c(2, 2), 
    col = c("red", "blue", "black"), 
    cex = 0.75)


```

```{r}
"A brief Summary of all the models:

Logistic Regression:

Accuracy 75.59%,
Sensitivity 75.75%
Specificity 75.53%
DecisionTrees:

Accuracy 78.1%,
Sensitivity 82.45%
Specificity 61.38%
RandomForest:

Accuracy 78.86%,
Sensitivity 82.46%
Specificity 63.99%"

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

